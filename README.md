# SpotifyRec
DS 210 Final Project Writeup
Keith Yu

## Overview
The dataset I chose to analyze was a [Spotify tracks dataset](https://huggingface.co/datasets/maharshipandya/spotify-tracks-dataset) containing tracks from over 100 different genres collected by Spotify’s Web API. The dataset of 114,000 tracks contains audio features for each track such as danceability, energy, valence, etc. and includes other information such as the artists involved in the production of the track, popularity of the track, and a unique track_id in case multiple tracks have the same song name. Using this dataset, I built a recommendation system that takes a track provided by the user and returns that 5 tracks based on a combined measure of how statistically close each of those tracks are to the original track and each track’s centrality. I split the project into a main file and two modules: record.rs and utils.rs

## Record.rs
In record, I set up the struct Record that I would use to store tracks for the rest of the project. Each field corresponds to a column in the dataset. In impl Record, I made a clean function to change the String fields to &str fields in order to have more flexibility in the rest of the project. The only library used in records is Serde, specifically its Serialize and Deserialize traits, which I use in other modules to unpack and sort the columns in the dataset into the correct fields for each instance of Record.

## Utils.rs
Utils has almost all of the functions I used in the project. I used the csv, petgraph, and std libraries in various functions throughout utils. The functions are described here and includes the function’s parameters/inputs and their types as well as an explanation of how each function works.

### read(path)
Read takes a file path as an input of type &str, reads the file, and returns a vector filled by instances of Record by using the from_reader trait to parse the CSV data. Then I used the deserialize trait and the map iterator to correctly sort each value into the corresponding fields in each instance. 
random_sample(input_path, output_path, sample_size)
random_sample takes three inputs: input_path (&str), output_path (&str), and sample_size (usize) and returns a file with a random sample of rows from the original file. input_path is the file path of the original file, output_path is the file path of the new file, and sample_size is the number of Records. random_sample selects. The first part of the function is a modified version of the read function, which I used to read and sort the original file. After initializing the rng generator, I shuffled the vector of Records created by the first part and chose the first sample_size amount of Records. This was written into a new CSV file, output_path. I then used a for loop to serialize the Records, reversing the deserialization that happened earlier. This function was used in the main function to select an arbitrary amount (I used 1000 in main) of random Records to make computation faster and easier.

### graph(records)
knn_graph takes one input, records (&[Record]) and creates a graph of nodes and edges from each node to their neighbors. I chose to limit the number of edges for each node to only neighbors that had similarity scores in the top 25th percentile of that node’s scores because checking if each of 114,000 nodes is close enough to any of the other 113,999 nodes in the graph to have an edge and then creating the edge, which was my original idea, would take too long. This in combination with limiting the size of the dataset being analyzed to a random sample of 1000 Records was necessary for efficiently testing and debugging this project. The function iterates through all the records given by records and adds each record as a node in the graph. The index of each node is also stored in a vector called nodes that is used later. There’s a println! statement to confirm each node was added. After creating the nodes, all the edges, the next for loop iterates over the node indices, with i representing the position in the vector that stores the nodes and &idx referencing the actual index in the graph. For every node, a vector of distances is created to store the distance between that Record and all the other Records in records. The for loop nested inside the current one does the same thing, iterating over the node indices. The current iteration of the outside loop is then compared to the current iteration of the inside loop. If they’re different records, the function will find how similar the two nodes are, which is derived from the Euclidean distance between the nodes, calculated in a later function. Since there’s a constantly changing set of Records, this for loop also prints out the names of the songs the loop is currently on. This lets the user see what songs are in the sample dataset and are available for them to input for recommendations. After all the distances for the outside node are calculated and stored in the distance vector with the distance, the distance vector is sorted. Then, there’s a for loop that iterates through the sorted vector and only adds an edge if the That loop adds the outside loop, the node in the distance vector, and the distance between the nodes as an edge in the graph. Finally, the function returns the graph.

### calc_centrality(graph)
calc_centrality takes one argument, a graph from the knn_graph function and calculates the centrality of each node in the graph by counting the edges for each node. The centrality of each node is then stored in a HashMap where the index of the node is the key and the amount of edges is the value. That HashMap is returned at the end of the function.

### index(records)
index takes an argument, records (&[Record]) and loops through records, adding the track_id of each Record to a HashMap as a key and the corresponding Record as a value. This function is used in a later function to get track information from the track_id.

### top(records, graph, song_name, centrality)
top takes four arguments, records (&[Record]), graph (&Graph<Record, f32>), song_name (&str), and centrality (&HashMap<NodeIndex, usize>) and returns the top recommendations for a given song. It takes the output of knn_graph() as graph and the output of calc_centrality() as centrality. song_name is the track_id of the song given by the user. After initializing a vector results to store the final recommendations and creating a variable map to store the results of index(), the function iterates through the nodes in the graph, comparing the track_id of the node with the given track_id. If there’s a match, the function retrieves the NodeIndex of the track and searches for the neighboring tracks from the graph, collecting all the neighbors and their centralities into a vector neighbors. Neighbors is then sorted by centrality and results takes the 5 tracks with the highest centralities. After that, the function prints out a message saying how many neighbors the track has, the track’s name, and the track’s artists. Finally, all the tracks and artists are printed out.

### euclidean_d(track1, track2)
euclidean_d takes two arguments, both of type &Record and finds the distance between the two Records using the difference in metrics such as danceability, energy, popularity, etc. Popularity is converted to be on a scale of 1, since it was originally on a scale of 100. It returns the Euclidean distance as an f32 value.

### sim_calc(track1, track2)
sim_calc takes the same arguments as euclidean_d and uses the function to get the Euclidean distance between Records before calculating the similarity score. The function normalizes the distance by dividing the distance by square root of 5, which was the maximum distance possible since I used 5 metrics in the distance calculation. I set the normalized distance to have a maximum of 1 and then subtracted that from 1 so that the smaller the distance is, the higher the similarity score is, which is returned as an f32 value. This function is used in knn_graph()

### search(data, track_name, artist)
search is a search function that takes three arguments, data (&Vec<Record>), track_name(&str), artist(&Option<str>). This used to account for the case that there are multiple songs with the same name but by different artists. If the user puts in an artist along with the track name, the function finds the track name in the vector of Records data and checks if the given artist is in that track’s artists. It keeps going until both the track names match and the artist has a match in the Record. If the user doesn’t put in an artist, the function just finds the first track that matches the given track. This is returned in an Option<Record> in case a matching track wasn’t found.

### Tests
Both test functions use the same instances of Record, with the test for knn_graph() using three other instances. The knn_graph() test makes sure the function returns the correct amount of nodes and the correct amount of edges. Both tests passed. The second test function, sim_test() tests the sim_calc() function to confirm that sim_calc() returns the correct similarity score. The first test in this function tested the similarity score for the same instance of Record, which should be 1 and the test passed. The second test tested the similarity score between two similar enough instances of Record, which should be in the range of 0.8 to 1, and the test also passed.

## Main.rs
Main starts by calling random_sample() to read the dataset.csv file and write the sample of 1000 Records into a different file dataset1.csv. That file is then read by calling the read function to store the Records into a vector (data), where clean() is called on each Record by iterating through each Record. Data then goes through graph() and creates a Graph (graph) and edges for each node. After calculating centrality using calc_centrality() on graph and storing it in the centrality variable, a loop starts, prompting the user to input a song and the song’s artist, which are stored in the track_name and artist_name variables, respectively. These two variables are put into search(), which also handles whether or not the user answered the prompt for an artist, and stores the resulting track in the found_track variable. After search() finds the track, the loop calls top(), using &data, &graph, and the track_id of &target_track and &centrality as its inputs and generates the top 5 recommendations for the user’s song before calling break on the loop and ending the program. In the case that search() can’t find the user’s song, the user is prompted to try again by typing in y or n for yes or no, respectively. If the user answers anything but y, break is called on the loop and the program ends. If y is the answer, the loop starts over from the original prompt.
